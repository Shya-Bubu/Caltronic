{
    "id": "monte-carlo-sampling-flashcards",
    "cards": [
        {
            "id": "mc-f1",
            "front": "Monte Carlo Estimation Formula",
            "back": "Ê[f(X)] = (1/N) Σ f(Xᵢ)\n\nAverage of N random samples.\nConverges to true E[f(X)] as N → ∞",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f2",
            "front": "Monte Carlo Error Scaling",
            "back": "Error ∝ σ / √N\n\nwhere σ = standard deviation of f(X)\n\nTo halve error: need 4× samples\nTo reduce by 10×: need 100× samples",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f3",
            "front": "Why is 1/√N convergence important?",
            "back": "It's DIMENSION-INDEPENDENT!\n\nTraditional methods: cost grows exponentially with dimension\nMonte Carlo: same 1/√N rate in any dimension\n\nKey advantage for high-dimensional problems.",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f4",
            "front": "Monte Carlo Integration Formula",
            "back": "∫ₐᵇ f(x)dx ≈ (b-a) × (1/N) Σ f(Xᵢ)\n\nwhere Xᵢ are uniform random in [a,b]\n\nWorks for any dimension!",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f5",
            "front": "What is Tolerance Analysis?",
            "back": "Determine output distribution given component variations.\n\n1. Sample component values from tolerance distribution\n2. Simulate circuit with those values\n3. Repeat 1000+ times\n4. Analyze output statistics",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f6",
            "front": "What is Yield Estimation?",
            "back": "Percentage of manufactured units meeting specs.\n\nMonte Carlo approach:\n1. Simulate many units with random variations\n2. Count how many pass specs\n3. Yield = (passing/total) × 100%",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f7",
            "front": "What is Importance Sampling?",
            "back": "Sample more from 'important' regions, weight results.\n\nBenefit: Reduces variance, faster convergence\nCost: Need to know which regions are important",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f8",
            "front": "What is a PRNG?",
            "back": "Pseudorandom Number Generator\n\nDeterministic algorithm that produces sequences LOOKING random.\n• Passes statistical tests\n• Reproducible if seed is set\n• Examples: Mersenne Twister, PCG",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f9",
            "front": "When to use Monte Carlo?",
            "back": "Good for:\n• High dimensions (>4-5)\n• Complex probability distributions  \n• Tolerance/yield analysis\n• When you have simulator but no formula\n\nNot good for:\n• Simple 1D integrals\n• When exact answer needed",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f10",
            "front": "SPICE .MC Command",
            "back": ".MC <runs> <analysis> <parameters>\n\nExample:\n.MC 1000 TRAN 1u 10u\n+ R1 10K DEV 5%\n\nRuns 1000 simulations with random R1 values.",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f11",
            "front": "Estimating π with Monte Carlo",
            "back": "1. Generate random (x,y) in [-1,1]×[-1,1]\n2. Check if x²+y² ≤ 1 (inside circle)\n3. π ≈ 4 × (inside count / total count)\n\nRatio of areas: πr²/4r² = π/4",
            "difficultyLevel": 1
        },
        {
            "id": "mc-f12",
            "front": "Law of Large Numbers",
            "back": "Sample average → true expected value as N → ∞\n\n(1/N) Σ Xᵢ → E[X]\n\nFoundation of all Monte Carlo methods!",
            "difficultyLevel": 1
        }
    ]
}